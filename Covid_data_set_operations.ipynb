{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n@Author: Venkatesh \\n\\n@Date: 2024-10-10 18:00:30 \\n\\n@Last Modified by: Venkatesh \\n\\n@Last Modified time: 2024-10-10 18:00:30 \\n\\n@Title : Program Aim to using pyspark to fetch data from covid data set performing operations\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "@Author: Venkatesh \\n\n",
    "@Date: 2024-10-10 18:00:30 \\n\n",
    "@Last Modified by: Venkatesh \\n\n",
    "@Last Modified time: 2024-10-10 18:00:30 \\n\n",
    "@Title : Program Aim to using pyspark to fetch data from covid data set performing operations\\n\n",
    "\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"COVID data death percentage analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-8LU844KJ:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>COVID data death percentage analysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b97f985c60>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To find out death percentage locally and globally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_death_percentage= spark.read.csv(\"C:/Users/Venkatesh Bingi/Downloads/worldometer_data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- TotalCases: integer (nullable = true)\n",
      " |-- NewCases: integer (nullable = true)\n",
      " |-- TotalDeaths: integer (nullable = true)\n",
      " |-- NewDeaths: integer (nullable = true)\n",
      " |-- TotalRecovered: integer (nullable = true)\n",
      " |-- NewRecovered: integer (nullable = true)\n",
      " |-- ActiveCases: integer (nullable = true)\n",
      " |-- Serious,Critical: integer (nullable = true)\n",
      " |-- Tot Cases/1M pop: integer (nullable = true)\n",
      " |-- Deaths/1M pop: double (nullable = true)\n",
      " |-- TotalTests: integer (nullable = true)\n",
      " |-- Tests/1M pop: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_death_percentage.printSchema()\n",
    "global_death_percentage.createOrReplaceTempView(\"covid_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+---------------------+\n",
      "|TotalDeaths|TotalConfirmed|GlobalDeathPercentage|\n",
      "+-----------+--------------+---------------------+\n",
      "|     713007|      19169166|                 3.72|\n",
      "+-----------+--------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_death_percentage_query = \"\"\"\n",
    "SELECT \n",
    "    SUM(TotalDeaths) AS TotalDeaths,\n",
    "    SUM(TotalCases) AS TotalConfirmed,\n",
    "    Round((SUM(TotalDeaths) / SUM(TotalCases)) * 100,3) AS GlobalDeathPercentage\n",
    "FROM covid_data\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(global_death_percentage_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "locally_death_percentage= spark.read.csv(\"C:/Users/Venkatesh Bingi/Downloads/Covid Problem-1/Covid Problem/covid_19_india.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sno: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- State/UnionTerritory: string (nullable = true)\n",
      " |-- ConfirmedIndianNational: string (nullable = true)\n",
      " |-- ConfirmedForeignNational: string (nullable = true)\n",
      " |-- Cured: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "locally_death_percentage.printSchema()\n",
    "locally_death_percentage.createOrReplaceTempView(\"covid_data_locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+----------------+\n",
      "|TotalDeaths|TotalConfirmed|Local_Percentage|\n",
      "+-----------+--------------+----------------+\n",
      "|   73389005|    5451678687|            1.35|\n",
      "+-----------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "locally_death_percentage_query=\"\"\"\n",
    "SELECT \n",
    "    SUM(Deaths) AS TotalDeaths,\n",
    "    SUM(Confirmed) AS TotalConfirmed,\n",
    "    ROUND((SUM(Deaths)/SUM(Confirmed))*100, 2) AS Local_Percentage\n",
    "FROM covid_data_locally\n",
    "\"\"\"\n",
    "spark.sql(locally_death_percentage_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To find out the infected population percentage locally and globally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Golabally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "globally_infected_percentage= spark.read.csv(\"C:/Users/Venkatesh Bingi/Downloads/worldometer_data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- TotalCases: integer (nullable = true)\n",
      " |-- NewCases: integer (nullable = true)\n",
      " |-- TotalDeaths: integer (nullable = true)\n",
      " |-- NewDeaths: integer (nullable = true)\n",
      " |-- TotalRecovered: integer (nullable = true)\n",
      " |-- NewRecovered: integer (nullable = true)\n",
      " |-- ActiveCases: integer (nullable = true)\n",
      " |-- Serious,Critical: integer (nullable = true)\n",
      " |-- Tot Cases/1M pop: integer (nullable = true)\n",
      " |-- Deaths/1M pop: double (nullable = true)\n",
      " |-- TotalTests: integer (nullable = true)\n",
      " |-- Tests/1M pop: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "globally_infected_percentage.createOrReplaceTempView(\"globally_infected\")\n",
    "globally_infected_percentage.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+---------------------+\n",
      "|TotalDeaths|TotalConfirmed|GlobalDeathPercentage|\n",
      "+-----------+--------------+---------------------+\n",
      "|     713007|      19169166|                 3.72|\n",
      "+-----------+--------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "globally_infected_percentage_query=\"\"\"\n",
    "SELECT \n",
    "\tSUM(CAST(Population AS bigint)),\n",
    "\tSUM(CAST(TotalCases AS bigint)),\n",
    "\tROUND((SUM(CAST(TotalCases AS float))/SUM(CAST(Population AS bigint))*100),2) AS total_infected_population_globally\n",
    "FROM globally_infected\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(global_death_percentage_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "locally_infected_percentage=spark.read.csv(\"C:/Users/Venkatesh Bingi/Downloads/worldometer_data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sno: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- State/UnionTerritory: string (nullable = true)\n",
      " |-- ConfirmedIndianNational: string (nullable = true)\n",
      " |-- ConfirmedForeignNational: string (nullable = true)\n",
      " |-- Cured: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "locally_death_percentage.printSchema()\n",
    "locally_death_percentage.createOrReplaceTempView(\"locally_infected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+----------------+\n",
      "|TotalDeaths|TotalConfirmed|Local_Percentage|\n",
      "+-----------+--------------+----------------+\n",
      "|   73389005|    5451678687|            1.35|\n",
      "+-----------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "locally_infected_percerntage_query=\"\"\"\n",
    "SELECT\n",
    "\tSUM(CAST(TotalSamples AS float)),\n",
    "\tSUM(CAST(Positive AS float)),\n",
    "    ROUND((SUM(CAST(Positive AS float)) / NULLIF(SUM(CAST(TotalSamples AS float)), 0) * 100), 2) AS total_infected_population_locally\n",
    "FROM locally_infected\n",
    "\"\"\"\n",
    "spark.sql(locally_death_percentage_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. To find out the countries with the highest infection rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_highest_infected_rates=spark.read.csv(\"C:/Users/Venkatesh Bingi/Downloads/worldometer_data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- TotalCases: integer (nullable = true)\n",
      " |-- NewCases: integer (nullable = true)\n",
      " |-- TotalDeaths: integer (nullable = true)\n",
      " |-- NewDeaths: integer (nullable = true)\n",
      " |-- TotalRecovered: integer (nullable = true)\n",
      " |-- NewRecovered: integer (nullable = true)\n",
      " |-- ActiveCases: integer (nullable = true)\n",
      " |-- Serious,Critical: integer (nullable = true)\n",
      " |-- Tot Cases/1M pop: integer (nullable = true)\n",
      " |-- Deaths/1M pop: double (nullable = true)\n",
      " |-- TotalTests: integer (nullable = true)\n",
      " |-- Tests/1M pop: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countries_highest_infected_rates.printSchema()\n",
    "countries_highest_infected_rates.createOrReplaceTempView(\"highly_infected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+---------------+--------------+\n",
      "|Country/Region|sum(TotalCases)|sum(Population)|infection_rate|\n",
      "+--------------+---------------+---------------+--------------+\n",
      "|         Qatar|         112092|        2807805|          3.99|\n",
      "| French Guiana|           8127|         299385|          2.71|\n",
      "|       Bahrain|          42889|        1706669|          2.51|\n",
      "|    San Marino|            699|          33938|          2.06|\n",
      "|         Chile|         366671|       19132514|          1.92|\n",
      "|        Panama|          71418|        4321282|          1.65|\n",
      "|        Kuwait|          70045|        4276658|          1.64|\n",
      "|          Oman|          80713|        5118446|          1.58|\n",
      "|           USA|        5032179|      331198130|          1.52|\n",
      "|  Vatican City|             12|            801|           1.5|\n",
      "+--------------+---------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countries_highest_infected_rates_query=\"\"\"\n",
    "SELECT \n",
    "    `Country/Region`, \n",
    "    SUM(TotalCases), \n",
    "    SUM(Population),  \n",
    "    ROUND( (SUM(TotalCases) / SUM(Population)  * 100), 2) AS infection_rate\n",
    "FROM \n",
    "    highly_infected\n",
    "GROUP BY\n",
    "    `Country/Region`    \n",
    "ORDER BY \n",
    "    infection_rate DESC\n",
    "limit 10    \n",
    "\"\"\"\n",
    "\n",
    "spark.sql(countries_highest_infected_rates_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. To find out the countries and continents with the highest death counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_highest_death_count=spark.read.csv(\"C:/Users/Venkatesh Bingi/Downloads/worldometer_data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- TotalCases: integer (nullable = true)\n",
      " |-- NewCases: integer (nullable = true)\n",
      " |-- TotalDeaths: integer (nullable = true)\n",
      " |-- NewDeaths: integer (nullable = true)\n",
      " |-- TotalRecovered: integer (nullable = true)\n",
      " |-- NewRecovered: integer (nullable = true)\n",
      " |-- ActiveCases: integer (nullable = true)\n",
      " |-- Serious,Critical: integer (nullable = true)\n",
      " |-- Tot Cases/1M pop: integer (nullable = true)\n",
      " |-- Deaths/1M pop: double (nullable = true)\n",
      " |-- TotalTests: integer (nullable = true)\n",
      " |-- Tests/1M pop: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countries_highest_death_count.printSchema()\n",
    "countries_highest_death_count.createOrReplaceTempView(\"countries_wise_death_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "|Country/Region|TotalDeaths|\n",
      "+--------------+-----------+\n",
      "|           USA|     162804|\n",
      "|        Brazil|      98644|\n",
      "|        Mexico|      50517|\n",
      "|            UK|      46413|\n",
      "|         India|      41638|\n",
      "|         Italy|      35187|\n",
      "|        France|      30312|\n",
      "|         Spain|      28500|\n",
      "|          Peru|      20424|\n",
      "|          Iran|      17976|\n",
      "+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countries_highest_death_count_query=\"\"\"\n",
    "SELECT \n",
    "    `Country/Region`,\n",
    "    ROUND(SUM(TotalDeaths),2) AS TotalDeaths\n",
    "FROM \n",
    "    countries_wise_death_count\n",
    "GROUP BY \n",
    "    `Country/Region`\n",
    "ORDER BY \n",
    "    TotalDeaths DESC  \n",
    "limit 10\n",
    "\"\"\"\n",
    "spark.sql(countries_highest_death_count_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_highest_death_count=spark.read.csv(\"C:/Users/Venkatesh Bingi/Downloads/worldometer_data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- TotalCases: integer (nullable = true)\n",
      " |-- NewCases: integer (nullable = true)\n",
      " |-- TotalDeaths: integer (nullable = true)\n",
      " |-- NewDeaths: integer (nullable = true)\n",
      " |-- TotalRecovered: integer (nullable = true)\n",
      " |-- NewRecovered: integer (nullable = true)\n",
      " |-- ActiveCases: integer (nullable = true)\n",
      " |-- Serious,Critical: integer (nullable = true)\n",
      " |-- Tot Cases/1M pop: integer (nullable = true)\n",
      " |-- Deaths/1M pop: double (nullable = true)\n",
      " |-- TotalTests: integer (nullable = true)\n",
      " |-- Tests/1M pop: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "continent_highest_death_count.printSchema()\n",
    "continent_highest_death_count.createOrReplaceTempView(\"continent_wise_death_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|        Continent|total_deaths|\n",
      "+-----------------+------------+\n",
      "|    North America|      229855|\n",
      "|           Europe|      205232|\n",
      "|    South America|      154885|\n",
      "|             Asia|      100627|\n",
      "|           Africa|       22114|\n",
      "|Australia/Oceania|         281|\n",
      "|             NULL|          13|\n",
      "+-----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "continent_highest_death_count_query=\"\"\"\n",
    "SELECT\n",
    "    Continent, \n",
    "    SUM(TotalDeaths) AS total_deaths\n",
    "FROM \n",
    "    continent_wise_death_count\n",
    "GROUP BY \n",
    "    Continent\n",
    "ORDER BY \n",
    "    total_deaths DESC;\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(continent_highest_death_count_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Average number of deaths by day (Continents and Countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "avarage_number_death_by_day_country=spark.read.csv(\"C:/Users/Venkatesh Bingi/Downloads/covid_19_clean_complete.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Province/State: string (nullable = true)\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Recovered: integer (nullable = true)\n",
      " |-- Active: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avarage_number_death_by_day_country.printSchema()\n",
    "avarage_number_death_by_day_country.createOrReplaceTempView(\"avarage_death_by_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|Country/Region|avg_deaths_per_day|\n",
      "+--------------+------------------+\n",
      "|            US|          58571.34|\n",
      "|United Kingdom|          21264.76|\n",
      "|        Brazil|          20946.99|\n",
      "|         Italy|           19721.9|\n",
      "|        France|          16215.55|\n",
      "|         Spain|          16133.14|\n",
      "|        Mexico|           9192.96|\n",
      "|         India|           5913.99|\n",
      "|          Iran|           5447.53|\n",
      "|       Belgium|           5125.95|\n",
      "|       Germany|           4634.69|\n",
      "|        Canada|            3721.1|\n",
      "|         China|           3576.66|\n",
      "|          Peru|           3468.69|\n",
      "|   Netherlands|           3310.18|\n",
      "|        Russia|            3294.6|\n",
      "|        Turkey|           2479.02|\n",
      "|        Sweden|           2387.84|\n",
      "|       Ecuador|           1843.71|\n",
      "|         Chile|           1715.32|\n",
      "+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avarage_number_death_by_day_query=\"\"\"\n",
    "SELECT \n",
    "    `Country/Region`, \n",
    "    ROUND(SUM(CAST(Deaths AS BIGINT)) / COUNT(DISTINCT Date),2) AS avg_deaths_per_day\n",
    "FROM \n",
    "    avarage_death_by_day\n",
    "GROUP BY \n",
    "    `Country/Region`\n",
    "ORDER BY \n",
    "    avg_deaths_per_day DESC; \n",
    "\"\"\"\n",
    "spark.sql(avarage_number_death_by_day_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.dropTempView(\"continent_wise_by_day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_wise_death_by_day=spark.read.csv(\"C:/Users/Venkatesh Bingi/Downloads/worldometer_data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- TotalCases: integer (nullable = true)\n",
      " |-- NewCases: integer (nullable = true)\n",
      " |-- TotalDeaths: integer (nullable = true)\n",
      " |-- NewDeaths: integer (nullable = true)\n",
      " |-- TotalRecovered: integer (nullable = true)\n",
      " |-- NewRecovered: integer (nullable = true)\n",
      " |-- ActiveCases: integer (nullable = true)\n",
      " |-- Serious,Critical: integer (nullable = true)\n",
      " |-- Tot Cases/1M pop: integer (nullable = true)\n",
      " |-- Deaths/1M pop: double (nullable = true)\n",
      " |-- TotalTests: integer (nullable = true)\n",
      " |-- Tests/1M pop: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "continent_wise_death_by_day.createOrReplaceTempView(\"Continent_Wise_Death_By_Day\")\n",
    "continent_wise_death_by_day.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|        Continent|avg_deaths_per_day|\n",
      "+-----------------+------------------+\n",
      "|           Africa|           3628.02|\n",
      "|             Asia|          20654.07|\n",
      "|Australia/Oceania|             72.18|\n",
      "|           Europe|          78134.58|\n",
      "|    North America|          14181.08|\n",
      "|    South America|          30222.54|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "continent_wise_death_by_day = \"\"\"\n",
    "SELECT \n",
    "    w.Continent,\n",
    "    ROUND(SUM(CAST(c.Deaths AS BIGINT)) / COUNT(DISTINCT c.Date),2) AS avg_deaths_per_day\n",
    "FROM \n",
    "    avarage_death_by_day c\n",
    "JOIN \n",
    "    Continent_Wise_Death_By_Day w\n",
    "ON \n",
    "    c.`Country/Region` = w.`Country/Region`\n",
    "GROUP BY \n",
    "    w.Continent\n",
    "ORDER BY \n",
    "    w.Continent;\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(continent_wise_death_by_day).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Average of cases divided by the number of population of each country (TOP 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "avarage_number_of_cases_by_country_wise=spark.read.csv(\"C:/Users/Venkatesh Bingi/Downloads/worldometer_data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- TotalCases: integer (nullable = true)\n",
      " |-- NewCases: integer (nullable = true)\n",
      " |-- TotalDeaths: integer (nullable = true)\n",
      " |-- NewDeaths: integer (nullable = true)\n",
      " |-- TotalRecovered: integer (nullable = true)\n",
      " |-- NewRecovered: integer (nullable = true)\n",
      " |-- ActiveCases: integer (nullable = true)\n",
      " |-- Serious,Critical: integer (nullable = true)\n",
      " |-- Tot Cases/1M pop: integer (nullable = true)\n",
      " |-- Deaths/1M pop: double (nullable = true)\n",
      " |-- TotalTests: integer (nullable = true)\n",
      " |-- Tests/1M pop: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avarage_number_of_cases_by_country_wise.printSchema()\n",
    "avarage_number_of_cases_by_country_wise.createOrReplaceTempView(\"avarage_cases_country_wise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|Country/Region|cases_per_population|\n",
      "+--------------+--------------------+\n",
      "|         Qatar|                3.99|\n",
      "| French Guiana|                2.71|\n",
      "|       Bahrain|                2.51|\n",
      "|    San Marino|                2.06|\n",
      "|         Chile|                1.92|\n",
      "|        Panama|                1.65|\n",
      "|        Kuwait|                1.64|\n",
      "|          Oman|                1.58|\n",
      "|           USA|                1.52|\n",
      "|  Vatican City|                 1.5|\n",
      "+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avarage_number_of_cases_by_country_wise_query=\"\"\" \n",
    "SELECT \n",
    "    `Country/Region`, \n",
    "    ROUND(SUM(CAST(TotalCases AS float)) / NULLIF(SUM(CAST(Population AS float)), 0)*100, 2) AS cases_per_population\n",
    "FROM \n",
    "    avarage_cases_country_wise\n",
    "GROUP BY \n",
    "    `Country/Region`\n",
    "ORDER BY \n",
    "    cases_per_population DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "spark.sql(avarage_number_of_cases_by_country_wise_query).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
